import csv
import networkx as nx
import pprint as pp

# code from lab lesson
def compute_good_local_community(graph, seed_node_id, alpha=0.9):
    #
    # Creation of the teleporting probability distribution for the selected node...
    map_teleporting_probability_distribution__node_id__probability = {}
    for node_id in graph:
        map_teleporting_probability_distribution__node_id__probability[node_id] = 0.
    map_teleporting_probability_distribution__node_id__probability[seed_node_id] = 1.
    #
    # Computation of the PageRank vector.
    map__node_id__node_pagerank_value = nx.pagerank(graph, alpha=alpha,
                                                    personalization=map_teleporting_probability_distribution__node_id__probability)
    #
    # Put all nodes in a list and sort the list in descending order of the “normalized_score”.
    sorted_list__node_id__normalized_score = [(node_id, score / graph.degree[node_id])
                                              for node_id, score in map__node_id__node_pagerank_value.items()]
    sorted_list__node_id__normalized_score.sort(key=lambda x: (-x[1], x[0]))
    #
    # LET'S SWEEP!
    index_representing_the_set_of_node_ids_with_maximum_conductance = -1
    min_conductance_value = float("+inf")
    set__node_ids_in_the_candidate_community = set()
    set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes = set(graph.nodes())
    for sweep_index in range(0, len(sorted_list__node_id__normalized_score) - 1):
        #
        # Creation of the set of nodes representing the candidate community and
        # its complement to the entire set of nodes in the graph.
        current_node_id = sorted_list__node_id__normalized_score[sweep_index][0]
        set__node_ids_in_the_candidate_community.add(current_node_id)
        set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes.remove(current_node_id)
        #
        # Evaluation of the quality of the candidate community according to its conductance value.
        conductance_value = nx.algorithms.cuts.conductance(graph,
                                                           set__node_ids_in_the_candidate_community,
                                                           set__node_ids_in_the_COMPLEMENT_of_the_candidate_community_to_the_entire_set_of_nodes)
        #
        # Discard local communities with conductance 0 or 1.
        if conductance_value == 0. or conductance_value == 1.:
            continue

        ###### PART ADDED FROM ORIGINAL CODE ######
        # Discard local communities with more than 140 Pokemons
        if len(set__node_ids_in_the_candidate_community) > 140:
            continue
        ################### END ###################

        #
        # Update the values of variables representing the best solution generated so far.
        if conductance_value < min_conductance_value:
            min_conductance_value = conductance_value
            index_representing_the_set_of_node_ids_with_maximum_conductance = sweep_index
    #
    # Creation of the set of nodes representing the best local community generated by the sweeping procedure.
    set__node_ids_with_minimum_conductance = set([node_id for node_id, normalized_score in
                                                  sorted_list__node_id__normalized_score[
                                                  :index_representing_the_set_of_node_ids_with_maximum_conductance + 1]])
    #
    return set__node_ids_with_minimum_conductance, min_conductance_value


# graph creation function same as part_2_1
def graph_create_from_tsv(tsvFilePath):
    # reading tsv file
    input_file_handler = open(tsvFilePath, 'r', encoding="utf-8")
    tsv_reader = csv.reader(input_file_handler, delimiter='\t')
    tsv_reader.__next__()
    list_adj = []
    # inserting adjacent pokemon couples in a list
    for pokemon in tsv_reader:
        pokemon1 = pokemon[0]
        pokemon2 = pokemon[1]
        list_adj.append((pokemon1, pokemon2))
    input_file_handler.close()

    # creating graph
    graph = nx.Graph()
    graph.add_edges_from(list_adj)
    return graph

# beginning of the code without func definitions
# given damping values
damp_val = [0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55,
            0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05]

graph = graph_create_from_tsv('dataset/pkmn_graph_data.tsv')
output_data = 'dataset/output.tsv'

# saving the nodes (pokemon) in a variable list
pkmn_nodes = list(graph.nodes)
# dictionary to store the frequency of a pokemon in a community
pkmn_freq = dict.fromkeys(list(graph.nodes), 0)

# list to store the rows needed
# (pokemon_name, number_of_nodes_in_the_local_community, conductance_value_of_the_local_community)
res = []
for perc, pokemon in enumerate(pkmn_nodes):
    # how much has been done, not really necessary for the final result, but useful to know if the code is OK
    print("{:.2%}".format(perc / len(pkmn_nodes)))
    set_local_comm = []
    for alpha in damp_val:
        # saving all the local community of the pokemon for every value of damp_val
        set_local_comm.append(compute_good_local_community(graph, pokemon, alpha=alpha))

    # best_min_cond_val calculates the minimum conductance value among every local_comm calculated
    # best_min_cond_val = [(set__node_ids_with_minimum_conductance, min_conductance_value)]
    # best_min_cond_val[0] = set__node_ids_with_minimum_conductance
    # best_min_cond_val[1] = min_conductance_value
    best_min_cond_val = min(set_local_comm, key=lambda x: x[1])
    res.append([pokemon, len(best_min_cond_val[0]), best_min_cond_val[1]])

    # calculating frequency of a pokemon in a community, for the second part of part_2_2
    for pkmn in best_min_cond_val[0]:
        pkmn_freq[pkmn] += 1

# writing tsv file to store the results
print('\n##############################')
print('###### Writing tsv file ######')
print('##############################\n')
# sorting the local_community in alphabetical order
res_alpha_order = list(sorted(res, key=lambda x: x[0]))
f = open(output_data, 'w')
f.write("pokemon_name\tnumber_of_nodes_in_the_local_community\tconductance_value_of_the_local_community" + "\n")
for row in res_alpha_order:
    f.write(str(row[0]) + "\t" + str(row[1]) + "\t" + str(row[2]) + "\n")
f.close()
print('############ DONE ############')

# calculating high and low frequency of a pokemon in descending order
sort_dict_desc = dict(sorted(pkmn_freq.items(), key=lambda x: x[1], reverse=True))
dict_len = len(sort_dict_desc)

print('\n##########################################')
print('###### Top 5 most frequent Pokemon  ######')
print('##########################################\n')
print('Pokemon\tFrequency\n')
for count, pokemon in enumerate(sort_dict_desc):
    if count >= 5:
        break
    print(str(pokemon) + '\t' + str(sort_dict_desc[pokemon]) + '\n')

print('\n###########################################')
print('###### Top 5 least frequent Pokemon  ######')
print('###########################################\n')
print('Pokemon\tFrequency\n')
for count, pokemon in enumerate(sort_dict_desc):
    if count < (dict_len - 5):
        continue
    print(str(pokemon) + '\t' + str(sort_dict_desc[pokemon]) + '\n')
